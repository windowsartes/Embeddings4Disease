model:
 type: BERT
 use_pretrained: false
 path_to_saved_weights: null
 config:
  hidden_size: 384
  num_attention_heads: 12
  num_hidden_layers: 12
tokenizer:
 use_pretrained: false
 path_to_saved_tokenizer: null
 path_to_vocab_file: data/vocab.txt
hyperparameters:
 batch_size: 1024
 seq_len: 24
storage_path: storage
training:
 device: cuda:0
 path_to_data: data/train_transactions_single.txt
 n_epochs: 100
 n_warmup_epochs: 50
 n_checkpoints: 1
 optimizer_parameters:
  learning_rate: 0.0001
  adam_beta1: 0.9
  adam_beta2: 0.999
  weight_decay: 0.01
validation:
 path_to_data: data/val_transactions_single.txt
 period: 1
 top_k: 10
 save_graphs: true
 metrics: 
  reciprocal_rank: true
  simplified_dcg: true
  precision: true
  recall: true
  f_score: true
  hit: true
save_trained_model: true